== Statistics Library ==
This library is used to collect statistics about Seattle nodes/vessels and then run specific analysis on the group of data. The library primarily deals with a custom data structure called a 'node_list' which is actually a dictionary of every node (unique key being the 'nodeid')

----
== Structure of a 'node_list' ==
 * Dictionary of Nodes, with keyword of its corresponding unique node id.  Contents of node id keyword is another dictionary with the following keywords:
   * '''timestamp''': a datetime object in the form of "datetime(2010, 2, 1, 22, 38, 21, 965646)", when the data was polled.
   * '''nodelocation''': 'ip:port'
   * '''responsetime''': a number in seconds corresponding to the time it took to run 'browse_node' (from the experiment library) on this specific node
   * '''version''': version of the node
   * '''nodeid''': unique node id of the node
   * '''vessels''': a list of vessel dictionaries (output of browse_node on the node) corresponding to the specific node
     * vesselhandle: 'nodeid:vesselname'
     * vesselname: name of the vessel, ie. "v1"
     * ownerkey: a dictionary with the the vessel's owner key, keys: 'e' and 'n'
     * nodelocation: 'ip:port'
     * userkeys: 0, 1 or >1 keys in a list where each key is a dictionary with keywords 'e' and 'n'
     * nodeid: unique node id of the node
     * version: version of the corresponding node
     * status: the status of the vessel at the time of polling
----
== Methods ==
 * '''poll_data'''()
   * Stores a collection of data (a 'node_list') relating to nodes/vessels and stores them into an external pickle also storing a seperate pickle of failed nodes (unparallelized completes in roughly 20min)
 * '''import_data'''(file_name)
   * Takes a file name (in pickle form) and returns a node_list
 * '''versions'''(node_list)
   * Returns a list of versions (strings) that exist in the current data
 * '''prod_beta_split'''(node_list)
   * Returns a list of 3 items: (0) list of production nodes, (1) list of beta nodes, (2) nodes with neither affiliation.
     * The actual items in each list are tuples (node_item, key name) where node_item is a node from the node_list and the key name corresponds to the production or beta key name it was matched with.
 * '''prod_beta_keys'''()
   * Returns a list of 2 maps with keywords corresponding to their public key names (ie. canonical.publickey is canonical):
     * map of production keys  from: [https://seattle.cs.washington.edu/browser/seattle/trunk/seattlegeni/node_state_transitions/statekeys statekeys]
     * map of beta keys with keywords from: [https://seattle.cs.washington.edu/browser/seattle/trunk/seattlegeni/node_state_transitions/statekeys_beta statekeys_beta]

----
== Example Uses == 
Script Contents:[[BR]]
(assumes 'poll_data()' was executed prior)
{{{
import stat_lib

def main():
  #location of poll data pickle
  nodes = stat_lib.import_data("nodedata_2_3_115/nodes_list.dat") 
  split(nodes)
  print "------------------"
  versions(nodes)

def versions(nodes):
  vers = stat_lib.versions(nodes)
  node_count = 0
  for key,nodes in vers.items():
    print str(key) + ": " + str(len(nodes))
    node_count = node_count + len(nodes)
  print "total nodes: " + str(node_count)

def split(nodes):
  pb_split = stat_lib.prod_beta_split(nodes)
  prod_nodes = pb_split[0]
  beta_nodes = pb_split[1]
  other_notes = pb_split[2]
  
  print "prod: " + str(len(prod_nodes))
  print "beta: " + str(len(beta_nodes))
  print "other: " + str(len(other_notes))
  print "total: " + str(len(prod_nodes) + len(beta_nodes) + len(other_notes))
  print "total nodes:" + str(len(nodes))

if __name__ == '__main__':
  main()
}}}
Console Output:
{{{
prod: 387
beta: 30
other: 2
total: 419
total nodes:419
------------------
0.1e: 1
0.1p-beta-r3467: 28
0.1c: 2
0.1b: 1
0.1m: 1
0.1l: 1
0.1o: 382
0.1n: 2
0.1p-beta-r3373: 1
total nodes: 419
}}}
