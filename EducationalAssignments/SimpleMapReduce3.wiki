= A Simple !MapReduce Framework =

Information about !MapReduce is available on the [wiki:RepyMapReduce main MapReduce page].

[[BR]]
[[BR]]

[[TOC(inline)]]
----
== Overview ==

In this first assignment, a simple one worker node and one primary node !MapReduce framework will be built.  The primary node will acquire data, hand it off to the worker, and wait for the worker to finish.  The worker will perform a map() pass and a reduce() pass on the data and send the result back to the primary node.  Since only one worker is involved in the computation, the partition step is left for future assignments.  This code will serve as a base for the future assignments that will expand the scalability and robustness of the framework.

== The Assignment ==
----
=== Step 1: The worker code ===

For the worker, begin with implementing a pipeline.  Where is the worker going to call its mapping function and reduce function from?  Put these calls in the script portion of the '''mapred.repy''' file, after ''if callfunc == 'initialize':''.  First, the worker needs to call a do_map function, giving the initial data as a parameter.  This data has a strict outline, where each line is treated as a key-value pair (separated by the ASCII character '''\n'''), and the key is separated from the value with a tab (first tab in the line, ASCII character '''\t'''). 

In order to ensure that the implementation of the worker stays general, we're going to enforce that any algorithmic-specific functionality be included in a separate file.  For this reason, mapper.repy and reducer.repy will need to be included at the top of the file.  These files will supply the map_func(key, value) and reduce_func(key, value_list) functions to the worker's do_map() and do_reduce() helper functions, respectively.  Two sample files (mapper.repy, reducer.repy) are included in the skeleton code.  After generating key-value pairs, the worker will call the map_func(key, value) function in mapper.repy for each key-value pair, collect the results, and return the list of key-value pairs generated by the do_map() function to the worker.

With the results from the do_map() function, do_reduce can now be called after some simplification.  The do_map function will have returned a list of (key, value) tuples, but the reduce_func expects a key with a list of values!  This means the worker will have to combine (key, value) tuples into a dictionary where the dictionary keys are keys and the dictionary values will be a list of values.  After this conversion, do_reduce() can be called while passing in this {key1: [v1, v2,..., vn], ..} dictionary.

Similar to do_map(), do_reduce() will call the reduce_func(key, value_list) for each key-values pair.  After collecting the results of reduce_func(), the key-value pairs can be expanded back out into the flat format as before ("'''key''' \t '''value''' \n").
[[BR]]
[[BR]]

=== Step 2: The primary code ===

In this step, the mappri.repy program will embody the preliminary design of how the primary node communicates with the single !MapReduce peer.


=== Step 3: Primary and worker communication ===

Messages!!

== Hints ==
 * Work sequentially!  Start with step 1 and ensure that if you directly feed in data that it will be mapped and reduced correctly.  Move onto developing the skeleton for step 2, and think about how you can pass strings using TCP messages for step 3.
 * 

== Notes ==

 * Make sure you do not call your own functions map(), reduce(), or hash().  These are built-in python methods, consider using other related names!

== What to turn in ==

Turn in a tar of your repy code including the following files:

 * '''mappri.repy''' - Your primary node code
 * '''mapred.repy''' - Your worker node code
 * '''README''' - A readme file detailing any bugs, limitations, or special operating instructions of your program